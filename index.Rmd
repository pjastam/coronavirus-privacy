---
title: "Coronavirus-apps: voorkomen is beter dan genezen"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Het kabinet kondigt twee apps aan voor het monitoren en beheersen van de
verspreiding van het coronavirus. Eén app "vertelt je of je in de buurt bent
geweest van een andere gebruiker, die besmet blijkt te zijn. Je krijgt dan het
advies om binnen te blijven’. De tweede app die het kabinet aankondigt is de al
bestaande app van het OLVG-ziekenhuis in Amsterdam. Door je temperatuur en
klachten over kortademigheid, keelpijn en verkoudheid in de app in te vullen,
kan een medisch team van een ziekenhuis aan de hand van RIVM-richtlijnen uw
risico op een besmetting en zorgbehoefte van een afstand inschatten.

Het kabinet onderzoekt of ze het gebruik van deze apps verplicht kan stellen,
maar benadrukt dat ze liever deelname op vrijwillige basis ziet. Maar een opt-in
mogelijkheid is geen keuze die in deze angstige tijd te lichtzinnig gemaakt moet
worden. Het biedt immers geen garantie dat onze data in goede handen komt en dat
onze privacy wordt gewaarborgd.

Het OLVG wil de data bijvoorbeeld in geanonimiseerde vorm voor wetenschappelijk
onderzoek gebruiken, wat in de algemene voorwaarden als secundair doel wordt
vermeld. Maar anonimisering hoeft geen garantie te bieden dat onze privacy wordt
gewaarborgd, want door koppeling van locatiegegevens en socialemediaberichten is
het mogelijk om de identiteit van personen alsnog te achterhalen.

Maar als opt-in en anonimisering onvoldoende zijn om onze privacy te garanderen,
is het dan überhaupt mogelijk om deze apps uit te rollen zonder dat onze privacy
op de tocht komt te staan? Die mogelijkheid is er zeker en wij doen hieronder
een aftrap voor een lijst met de privacyvoorwaarden waaraan deze apps dan moeten
voldoen.

Privacyvoorwaarden
==================

Een vruchtbare weg om bij de realisatie van de apps onze privacy te borgen is
als we komen tot een lijst van voorwaarden c.q. een beschrijving van een
situatie waarin het delen van persoonlijke data vanuit Europese normen en
waarden aanvaardbaar is. Apps kunnen dan aan de hand van deze lijst volgens het
principe ‘privacy by design’ ontworpen en gebouwd worden. Hieronder volgt onze
aftrap voor zo’n lijst met noodzakelijke voorwaarden:

<details>
<summary>
**Hoger doel**: De apps moeten een hoger algemeen sociaal doel dienen. Dat doel moet helder verwoord en afgebakend zijn.
</summary>
Het is evident dat er in dit geval sprake is van zo’n hoger doel, namelijk het
tegengaan van de verspreiding van het coronavirus in ons land. Maar het is niet
zonder meer zo dat het in algemene zin uitvoeren van wetenschappelijk onderzoek
op deze data, het secundaire doel, dat ook is. De nog te formuleren specifieke
wetenschappelijke onderzoeksvragen zijn bij de keuze om de apps te gebruiken
immers niet bekend bij de gebruiker, dus die weet niet waarvoor hij nu
toestemming geeft. Het is in ieder geval niet het primaire doel van het kabinet
om deze data voor wetenschappelijk onderzoek te verzamelen.
</details>

<details>
<summary>
**Afgebakende periode**: Als het hogere doel het beteugelen van een crisis is, dan moet er een afgebakende periode van datadeling zijn. Deze periode kan eventueel verlengd worden omdat de crisis nog niet bezworen is. Deze besluitvoming moet voldoen aan democratische uitgangspunten.
</summary>
Het risico van in crisistijd ingevoerde maatregelen is dat de tijdelijkheid
ervan in de geschiedenis een rekbaar begrip is gebleken, daarom zijn harde
afspraken hierover noodzakelijk. Een afgebakende periode kan zijn om de data te
delen zolang de crisis nog niet bezworen is. Om te kunnen vaststellen of de
crisis is bezworen zullen een aantal objectieve beoordelingscriteria moeten
worden geformuleerd. Een voorbeeld daarvan is de verspreidingscoefficient, i.e.
het aantal mensen dat wordt besmet als ze met één besmet persoon in contact
komen. Het streven van het RIVM is om die verspreiding coëfficiënt (langdurig)
onder de 1 te houden, het is goed om daarbij een vaste ondergrens gedurende een
vaste periode af te spreken.
</details>

<details>
<summary>
**Data verwijderen**: Als het hogere doel gerealiseerd is, dan moet de gedeelde data verwijderd worden.
</summary>
Hier luistert het nauw of naast het primaire doel van de apps ook secundaire
doelen als hoger doel worden betiteld. Als alleen het primaire doel van de
verspreiding van het coronavirus wordt nagestreefd, dan dienen alle data te
worden verwijderd nadat dat doel is bereikt.

Als het secundaire doel van het uitvoeren van wetenschappelijk onderzoek ook als
hoger doel wordt geaccepteerd, dan is het sterk de vraag hoe lang deze data nog
bewaard gaan worden. Een gemiddeld promotietraject van een promovendus aan de
universiteit duurt langer dan 4 jaar, wat al substantieel langer is dan de
maximale bewaartermijn van 2 jaar die onderdeel is van de algemene voorwaarden
van de app van het OLVG.
</details>

<details>
<summary>
**Gegevens onder beheer van de gebruikers zelf**: Data moet zo veel mogelijk bij de bron / eigenaar blijven en zo min mogelijk als kopieën in datawarehouses / hubs / markets / lakes worden opgeslagen.
</summary>
Idealiter blijft de data die in de apps worden ingevuld op de mobiele telefoon
van degene staan die die data invult en worden de bewerkingen op de data
decentraal uitgevoerd. Alleen de geaggregeerde resultaten van de lokaal bewerkte
data komen dan terecht bij de instanties die deze stuurinformatie nodig hebben,
denk aan het ziekenhuis, het RIVM of de GGD. Dit is de werkwijze van de Personal
Health Train, het concept dat Minister Bruins propageert[^1] en is ontwikkeld
door DTL, MAASTRO en LUMC[^2].

Deze werkwijze is des te meer van belang om te voorkomen dat de data ten behoeve
van het secundaire doel op vele plekken terecht komt. Daarbij is er de
voorwaarde dat de data die voor primaire en secundaire doelen centraal getrokken
wordt, met de vereiste beveiligingsmaatregelen wordt beheerd.
</details>

<details>
<summary>
**Bescherming van belangen**: Er moet adequate wet- & regelgeving om het gebruik van de apps gebouwd zijn, incl. toezichthoudende en rechtsprekende organen, zodat bij het schenden van belangen onafhankelijk recht gesproken kan worden.
</summary>
Deze randvoorwaarde ligt voor de hand. Nagegaan moet worden of de algemene
verordening gegevensbescherming (AVG) volstaat of dat aanvullende of bijgestelde
wetgeving noodzakelijk is. Het is daarbij onder meer van belang dat individuele
burgers het recht hebben om misbruik van hun data te melden en het stop zetten
daarvan te kunnen afdwingen.
</details>

<details>
<summary>
**Governance structuur**: De besluitvorming over de ontwikkeling en het gebruik van de apps en de verzamelde data, moet zodanig zijn ingericht dat belangen evenwichtig worden gediend.
</summary>
Bits of Freedom noemt het kabinet als de ‘governance body’. Dat is ons inziens
een onvoldoende invulling van deze randvoorwaarde[^3]. Dat geeft te weinig
invloed, voor direct betrokkenen en maakt geen gebruik van de noodzakelijke
expertise voor een goede besluitvorming (de meeste volksvertegenwoordigers
hebben weinig expertise van big data, AI en van technieken waarmee op grote
schaal data wordt verzameld). Van belang is dat de governance structuur een
evenwichtige vertegenwoordiging van belangenpartijen kent: overheid,
bedrijfsleven en burgers.
</details>

<details>
<summary>
**Gezonde prikkels**: Het systeem moet het gewenste datadelinggedrag stimuleren (en ongewenst gedrag tegen gaan).
</summary>
Over het ongewenste gedrag van datadelen op de bekende sociale platforms is de
afgelopen jaren al veel gepubliceerd. Deze platforms zetten zeer succesvol aan
tot het delen van data, maar er zijn inmiddels diverse kanttekeningen gezet bij
het gebruik van de (persoons)data voor doeleinden die inbreuk maken op onze
privacy. In feite komt deze randvoorwaarde er op neer dat burgers niet verleid worden tot
meer datadeling dan nodig om het hogere doel te dienen en niet verdiend wordt
aan datadeling.
</details>

<details>
<summary>
**Data aan de bron anoniem houden**: Data moet geanonimiseerd worden, maar dat is zoals eerder gezegd op zich nog geen voldoende voorwaarde.
</summary>
Uit Amerikaans onderzoek op basis van de volkstelling in 1990 is gebleken dat
veel individuen binnen geografisch afgebakende populaties combinaties van
demografische kenmerken hebben die niet vaak voorkomen.[^4] Een verrassend
resultaat was dat slechts drie kenmerken (postcode, geslacht en geboortedatum)
87% van alle Amerikanen (bijna) uniek maakt. Met drie andere kenmerken
(woonplaats, geslacht en geboortedatum) geldt dat voor 53% van de totale
Amerikaanse bevolking. Merk hierbij op dat in datasets in het algemeen meer dan
drie gegevens per persoon worden vastgelegd.

Geanonimiseerde data, zeker data die ook gezondheidskenmerken bevatten, kunnen
dus niet zonder meer als anoniem worden gezien. Deze constatering is relevant
met betrekking tot het primaire doel van de dataverzameling, maar zeker ook met
betrekking tot het secundaire doel. Als er voor dat laatste doel al data
gebruikt gaan worden, dan is het verstandig om daarvoor alleen een minimale
dataset beschikbaar te stellen waarmee de (nog nader te formuleren specifieke)
wetenschappelijke onderzoeksvraag voldoende beantwoord kan worden.
</details>

<details>
<summary>
**Transparantie**: Bedrijven zullen de oplossing waarschijnlijk gaan realiseren omdat het de overheid aan technische expertise ontbreekt. Dat vereist transparantie over het gebruikte bedrijfsmiddel.
</summary>
Het OLVG heeft aangekondigd dat zij de verzamelde data openbaar wil aanbieden
aan wetenschappelijke onderzoekers. Gezien de overige randvoorwaarden is het de
vraag of dit acceptabel is voor degenen wiens data het betreft. In ieder geval
moet de verzamelde data door auditors in te zien zijn.

Voor de invulling van de randvoorwaarde van transparantie is het essentieel dat
de broncode van de app openbaar wordt gemaakt. Hierdoor kan iedere burger zelf
controleren waar de in de app ingevoerde data naartoe stroomt en welke
bewerkingen daarop worden uitgevoerd. Hierbij dient te worden aangetekend dat
code slecht door een beperkt gedeelte van de bevolking gelezen kan worden.
Experts kunnen hun bevindingen wel in lekentaal formuleren en delen. Een andere
belangrijke maatregel is dat de resultaten van de bewerkingen door derden moeten
kunnen worden gereproduceerd.
</details>

<details>
<summary>
**Validiteit en betrouwbaarheid**: Validiteit en betrouwbaarheid zijn statistische criteria die vereisen dat met de apps daadwerkelijk wordt gemeten wat men beoogt te meten. En dat toeval daarbij een zo klein mogelijke rol speelt.
</summary>
Het eerder geformuleerde criterium van het hogere doel vereist niet alleen dat
er sprake is van het bestaan van een hoger doel, maar ook dat daarmee het hogere
doel wordt gediend. Dat vereist helderheid over hoe de apps, de data en de
vervolgmaatregelen dit doel gaan bereiken en hoe bijgestuurd wordt richting dat
doel. Laat dus zien hoe succesvol men is in het bereiken van dat doel. Het
risico is aanwezig dat de twee apps op dit moment niet aan dit criterium
voldoen, aangezien in de antwoorden van het RIVM op veelgestelde vragen staat
dat er nog steeds geen zekerheid is over het ontstaan van immuniteit en de duur
daarvan.
</details>

Oproep aan het kabinet
======================

Wij hopen dat het kabinet alleen besluit tot inzet van apps met borging van onze
privacy. Zeker als die apps verplicht worden gesteld, maar evenzeer als deze op
vrijwillige basis te gebruiken zijn. Tot op heden is er geen sluitend bewijs dat
het inzetten van apps het hogere doel dient. ‘Baat het niet, schaadt het niet’
gaat hier niet op!

Onze zorgen over de verspreiding van het coronavirus zijn groot, maar onze
privacy is ook een groot goed en angst is een slechte raadgever. In alle
opzichten geldt: ‘voorkomen is beter dan genezen’.

[^1]: <https://www.rijksoverheid.nl/documenten/kamerstukken/2018/11/15/kamerbrief-over-data-laten-werken-voor-gezondheid>

[^2]: <https://www.dtls.nl/fair-data/personal-health-train/>

[^3]: <https://www.bitsoffreedom.nl/2020/03/20/privacy-is-geen-absoluut-recht-maar-wel-een-noodzaak/>

[^4]: <http://privacytools.seas.harvard.edu/files/privacytools/files/paper1.pdf>
